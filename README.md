# Hackathon @ PracticalD2T 2023
This repository contains instructions, code, and data for the hackathon at the [**PracticalD2T workshop**](https://practicald2t.github.io) which takes place on 11 Sep 2023 at SIGDIAL/INLG, Prague.

## Main Task: Weather Forecast Generation üå¶Ô∏è

Your task is to build a system for automatically **generating weather forecasts**. 

The system will have access to [OpenWeather API](https://openweathermap.org/api) which provides access to up-to-date weather from anywhere in the world.

The forecasts should be:
- automatically generated by **open-source code** (+ if possible, open language models),
- **human-readable**,
- **accurate** with respect to the input data,
- concise, complete, captivating, insightful, etc. (as much as possible).

### Data Access
For starters, you can find a set of Python scripts for interacting with the [OpenWeather API](https://openweathermap.org/api) in the `scripts/openweather` directory.

You can use each script in either online or offline mode:
- for **online** use, use the argument `-l` / `--location` which is a free-form string describing an address anywhere around the world, e.g. "Prague, Czechia". (The location gets automatically geocoded to GPS coordinates using the [Nominatim](https://nominatim.org) library.)
- for **offline** use, use the argument `-j`/`--json` which is a path to the downloaded JSON file. (This is the preffered form of using the scripts, see the *API key* section).

The script outputs the response a pretty-printed chart, using only a **subset of data**. Feel free to go through the [docs](https://openweathermap.org/api) and extract the data from the response you actually need!

On [free tier](https://openweathermap.org/price), OpenWeather API provides access to the following data which we will use for the task:
- [current weather](https://openweathermap.org/current)
- [5-day forecast (with 3-hour resolution)](https://openweathermap.org/forecast5)
- [air pollution](https://openweathermap.org/api/air-pollution)



#### API key
You will be given to a shared OpenWeather API key. The key is on free tier which is **limited to 1000 requests per day**. 

Please, use it solely for **pre-downloading several data files** for the locations and dates of your choice (up to 1000 requests divided by # of teams) and use the downloaded files for development and testing.

To get extra requests, you can create your own free account(s).


#### Data files
In the `data` folder, you can find pre-downloaded files for various locations.

TODO details

### ‚òÄÔ∏è Subtask #1: Generate the current weather description
The task is to generate a **description of the current weather** in the city(-ies) of your choice.

The system should be flexible enough to work with different kinds of conditions and values, emphasizing the important features of the current weather.

See the [**current weather API**](https://openweathermap.org/current) description for details.

### üå¶Ô∏è Subtask #2: Generate a 5-day forecast
The task is to generate a **5-day forecast** for the city(-ies) of your choice.

The forecast should contain both the general outlook and the details about individual days, drawing on differences and/or similarities between the days to make the description fluent and coherent

See the [**forecast API**](https://openweathermap.org/forecast5) description for details.

### üå¨Ô∏è Subtask #3: Generate air pollution report
The task is to generate an **air pollution** report for the city(-ies) of your choice.

The report should be useful for the city inhabitants. Therefore, it should not contain only a "dry" description of the values, but also relevant recommendations.

See the [**air pollution API**](https://openweathermap.org/air-pollution) description for details.

### üá∫üá≥ Subtask #4: Generate a weather forecast in the local language [ADVANCED]
If you are feeling adventurous, you may extend any of the previous tasks to the multilingual setting. 

In particular, it would be useful to generate the weather report in the local language of the city. 

How many languages can your system handle at once?

### Evaluation
The most important part of the hackathon is **evaluating the quality of the generated reports**. 

Various axes you should evaluate the output on:

- **fluency** - Is the report without syntactical / grammatical errors and is it easily readable?
- **semantic accuracy** - Is the report faithful to the input data, or does it contain false information?
- **completeness** - Does the report contain all the features you wanted to include?
- **consistency** - Is the system able to produce outputs consistently across various inputs?

You have several options on how to perform the evaluation:

#### Referenceless Automatic Metrics
Referenceless metrics take as an input the generated output alone. 

These metrics can help us evaluate the **fluency and readability** of the outputs.

- **LM perplexity** -  How much is a selected language model *likely* to generate the report? (see [perplexity on HF metrics](https://huggingface.co/spaces/evaluate-metric/perplexity))
- **Quality Estimation** - What is the estimated quality of the report based on the report alone? (see [COMET-QE](https://huggingface.co/spaces/evaluate-metric/comet/blob/main/README.md), [GEMBA](https://arxiv.org/pdf/2302.14520.pdf))


#### Automatic Metrics: Reference-based
Reference-based metrics take as input the generated output and a reference. 

Since we generally do not have human-written references, we need to focus on the metrics that compare the generated text to the input data. These metrics can help us evaluate the **semantic accuracy** of the output.

- **NLI** - Are all of the output facts entailed in the input data and vice versa? (see [nlgi](https://github.com/ufal/nlgi_eval), you can ask Zdenƒõk for help)
- **QuestEval** - Is it possible to answer questions from the output based on the input data? (see [QuestEval](https://github.com/ThomasScialom/QuestEval))
- standard **semantic overlap metrics** - [BERTScore](https://huggingface.co/spaces/evaluate-metric/bertscore), [BLEURT](https://huggingface.co/spaces/evaluate-metric/bleurt), etc., - Is the semantics of the output close to the semantics of the input?
  -  using input data as references, potentially first transforming the input to text with simple templates


#### Manual Evaluation
Close the end of the hackathon, we plan to perform a small-scale **in-house manual evaluation** .

The idea is to **let other hackathon participants evaluate the outputs** of your model. 

For the evaluation process, you should prepare a randomly-selected subset of outputs of your system you want to evaluate.

We will specify the details based on the progress and ambitions of individual teams.

## Alternative Tasks

### Our World In Data

The server [Our World In Data](https://ourworldindata.org/) provides [open data](https://github.com/owid/owid-datasets/tree/master/datasets) in machine-readable format on many interesting topics, including [climate change](https://ourworldindata.org/charts#climate-change), [COVID-19](https://ourworldindata.org/charts#covid-19), or [Annual scholarly publications on AI](https://ourworldindata.org/grapher/annual-scholarly-publications-on-artificial-intelligence).

You can download each data source underlying the chart in a CSV format.

The basic task is: "automatically generate a caption for the chart of your choice". 

But of course, you can be more creative. What about "report interesting trends" or "describe connections across charts"?

### Report on LLM data processing capabilities

This task is a bit more investigative. The goal is to compile a table with capabilities of different LLMs to "digest" different kinds of structured inputs.

 Which models can work from scratch with CSV, JSONs, etc.? And do the accept any input, or are there any cases which cause problems (abbreviations in headers, missing headers, deep nesting, ...)?

The ultimate goal is then to find cases where the LLMs **cannot** successfully process structured data ‚Äì the output either contains hallucinations or does not make sense at all.

The inputs can be either handcrafted or syntethically generated, the outputs should generally contain descriptions / summaries of the data. Your task is to evaluate and annotate the outputs.

### Explainable data-to-text generation
This task is more linguistically-oriented, and can be in principle combined with any of the previous tasks. The goal is to generate **intermediate representations** of the output text that would help with controlling the output and explain the reasoning process of the model.

The intermediate representations can be on the different levels of abstraction: predicate-argument, deep syntax, surface syntax, etc. (see some of the intermediate representations [here](https://aclanthology.org/W19-8659/)).

The representations should be faithful both to the input data and to the output text, providing an additional level of control over the model.

Besides the inputs from the previous tasks, you can also use some of the more standard data-to-text datasets such as [WebNLG](https://huggingface.co/datasets/web_nlg), [E2E](https://huggingface.co/datasets/GEM/e2e_nlg), or [SportSett:Basketball](https://github.com/nlgcat/sport_sett_basketball). For quick visualization and easy loading of these (and many other) data-to-text datasets you can use [Tabgenie](https://github.com/kasnerz/tabgenie) ([live demo](http://quest.ms.mff.cuni.cz/rel2text/tabgenie)).


*(Credits to Simon Mille for coming up with the last two tasks.)*

## Outcome & Takeaways


## LLM access
TODO our API


### Google Colab
Alternatively, you can use Google Colab notebooks.

**Advantages:** You do not need to rely on our infrastructure, you can re-use existing Jupyter notebooks and you can use the web-ui interface for rapid development.

**Disadvantages:** It may be harder to integrate the notebooks with your custom codebase. Also, the GPUs may not be available or sufficient for the models you want to run.

**Useful links**:
- https://github.com/camenduru/text-generation-webui-colab - colab notebooks for running [text-generation-webui](https://github.com/camenduru/text-generation-webui) with various LLMs